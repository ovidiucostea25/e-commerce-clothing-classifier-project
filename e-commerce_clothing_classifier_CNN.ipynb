{"cells":[{"source":"![clothing_classification](clothing_classification.png)\n","metadata":{},"id":"aaa02648-9eae-45ba-893f-88440e8e4235","cell_type":"markdown"},{"source":"Fashion Forward is a new AI-based e-commerce clothing retailer.\nThey want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n\nAs a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc.","metadata":{},"id":"ad5a988c-1095-485a-a88c-002400a872be","cell_type":"markdown"},{"source":"# Run the cells below first","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1744716268475,"lastExecutedByKernel":"76e52114-bd9b-4866-84e1-9d661d94991c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the cells below first"},"id":"4a1ab317-f3e4-4e5f-93a7-9c27677c5ffb","cell_type":"code","execution_count":8,"outputs":[]},{"source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1744716268526,"lastExecutedByKernel":"76e52114-bd9b-4866-84e1-9d661d94991c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"id":"ea8065b7-84fc-4376-afef-6db731dec4b3","cell_type":"code","execution_count":9,"outputs":[]},{"source":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{"executionCancelledAt":null,"executionTime":129,"lastExecutedAt":1744716268655,"lastExecutedByKernel":"76e52114-bd9b-4866-84e1-9d661d94991c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":80,"type":"stream"},"1":{"height":38,"type":"stream"},"2":{"height":122,"type":"stream"},"3":{"height":38,"type":"stream"},"4":{"height":122,"type":"stream"},"5":{"height":38,"type":"stream"},"6":{"height":122,"type":"stream"},"7":{"height":38,"type":"stream"},"8":{"height":59,"type":"stream"}}},"id":"662e1bf1-943f-4243-9fd4-02ce11609e8d","cell_type":"code","execution_count":10,"outputs":[]},{"source":"# Create DataLoaders for training and testing\nbatch_size = 64\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1744716268711,"lastExecutedByKernel":"76e52114-bd9b-4866-84e1-9d661d94991c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create DataLoaders for training and testing\nbatch_size = 64\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"},"id":"53c0a71d-d7d9-4a11-8a9b-55867ea7e0b5","cell_type":"code","execution_count":11,"outputs":[]},{"source":"# 1. Define the CNN architecture\n\nclass GarmentClassifier(nn.Module):\n    def __init__(self):\n        super(GarmentClassifier, self).__init__()\n        # Convolutional layer: 1 input channel (grayscale), 32 output channels, kernel size 3\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n        # Rectified Linear Unit activation\n        self.relu = nn.ReLU()\n        # Pooling layer: 2x2 max pooling reduces spatial dimensions by half\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        # Fully connected layer:\n        # Image dimensions reduce from 28x28 to 14x14 after pooling, so input features = 32 * 14 * 14\n        # Output features = 10 (one per class)\n        self.fc1 = nn.Linear(32 * 14 * 14, 10)\n    \n    def forward(self, x):\n        # Apply convolution, activation, and pooling\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        # Flatten the output tensor for the fully connected layer\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        return x","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1744716268762,"lastExecutedByKernel":"76e52114-bd9b-4866-84e1-9d661d94991c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# 1. Define the CNN architecture\n\nclass GarmentClassifier(nn.Module):\n    def __init__(self):\n        super(GarmentClassifier, self).__init__()\n        # Convolutional layer: 1 input channel (grayscale), 32 output channels, kernel size 3\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n        # Rectified Linear Unit activation\n        self.relu = nn.ReLU()\n        # Pooling layer: 2x2 max pooling reduces spatial dimensions by half\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        # Fully connected layer:\n        # Image dimensions reduce from 28x28 to 14x14 after pooling, so input features = 32 * 14 * 14\n        # Output features = 10 (one per class)\n        self.fc1 = nn.Linear(32 * 14 * 14, 10)\n    \n    def forward(self, x):\n        # Apply convolution, activation, and pooling\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        # Flatten the output tensor for the fully connected layer\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        return x"},"cell_type":"code","id":"b9c44e20-e568-4ece-b650-cacd01fc566e","outputs":[],"execution_count":12},{"source":"# 2. Training the CNN\n\n# Use GPU if available, otherwise CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GarmentClassifier().to(device)\n\n# Define loss criterion and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop (2 epochs)\nepochs = 2\nmodel.train()\nfor epoch in range(epochs):\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()       # Clear previous gradients\n        outputs = model(inputs)       # Forward pass\n        loss = criterion(outputs, labels)   # Compute loss\n        loss.backward()             # Backward pass\n        optimizer.step()            # Update model parameters\n        \n        running_loss += loss.item()\n    \n    avg_loss = running_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"cb81ad28-125c-4bb7-9faf-ba887dac9987","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/2, Loss: 0.4354\nEpoch 2/2, Loss: 0.3042\n"}],"execution_count":13},{"source":"# 3. Testing the model \n\nmodel.eval()\npredictions = []  \nall_labels = []   \n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        # Get the predicted class (highest score)\n        _, preds = torch.max(outputs, 1)\n        predictions.extend(preds.cpu().numpy().tolist())\n        all_labels.extend(labels.cpu().numpy().tolist())\n\n# Convert predictions and true labels to tensors for metric calculations\npreds_tensor = torch.tensor(predictions)\nlabels_tensor = torch.tensor(all_labels)\n\n# Define torchmetrics for accuracy, per-class precision, and per-class recall.\n# We specify task=\"multiclass\" and num_classes=10 (for FashionMNIST).\naccuracy_metric = Accuracy(task=\"multiclass\", num_classes=10)\nprecision_metric = Precision(task=\"multiclass\", num_classes=10, average=None)\nrecall_metric = Recall(task=\"multiclass\", num_classes=10, average=None)\n\n# Calculate metrics\naccuracy = accuracy_metric(preds_tensor, labels_tensor).item()\nprecision = precision_metric(preds_tensor, labels_tensor).tolist()  \nrecall = recall_metric(preds_tensor, labels_tensor).tolist()         \n\nprint(f\"\\nTest Accuracy: {accuracy:.4f}\")\nprint(\"Per-class Precision:\", precision)\nprint(\"Per-class Recall:\", recall)","metadata":{"executionCancelledAt":null,"executionTime":5506,"lastExecutedAt":1744716368622,"lastExecutedByKernel":"76e52114-bd9b-4866-84e1-9d661d94991c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# 3. Testing the model \n\nmodel.eval()\npredictions = []  \nall_labels = []   \n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        # Get the predicted class (highest score)\n        _, preds = torch.max(outputs, 1)\n        predictions.extend(preds.cpu().numpy().tolist())\n        all_labels.extend(labels.cpu().numpy().tolist())\n\n# Convert predictions and true labels to tensors for metric calculations\npreds_tensor = torch.tensor(predictions)\nlabels_tensor = torch.tensor(all_labels)\n\n# Define torchmetrics for accuracy, per-class precision, and per-class recall.\n# We specify task=\"multiclass\" and num_classes=10 (for FashionMNIST).\naccuracy_metric = Accuracy(task=\"multiclass\", num_classes=10)\nprecision_metric = Precision(task=\"multiclass\", num_classes=10, average=None)\nrecall_metric = Recall(task=\"multiclass\", num_classes=10, average=None)\n\n# Calculate metrics\naccuracy = accuracy_metric(preds_tensor, labels_tensor).item()\nprecision = precision_metric(preds_tensor, labels_tensor).tolist()  \nrecall = recall_metric(preds_tensor, labels_tensor).tolist()         \n\nprint(f\"\\nTest Accuracy: {accuracy:.4f}\")\nprint(\"Per-class Precision:\", precision)\nprint(\"Per-class Recall:\", recall)","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"132bdc79-f76c-43e4-a137-2471844bfad0","outputs":[{"output_type":"stream","name":"stdout","text":"\nTest Accuracy: 0.8907\nPer-class Precision: [0.8448275923728943, 0.9788944721221924, 0.879133403301239, 0.8385370373725891, 0.8109405040740967, 0.9856410026550293, 0.7114583253860474, 0.9333333373069763, 0.9624876379966736, 0.9628514051437378]\nPer-class Recall: [0.8330000042915344, 0.9739999771118164, 0.7710000276565552, 0.9399999976158142, 0.8450000286102295, 0.9610000252723694, 0.6830000281333923, 0.9660000205039978, 0.9750000238418579, 0.9589999914169312]\n"}],"execution_count":14}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}